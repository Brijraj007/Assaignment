{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445e5ffa-be1e-4c56-b3bd-b8e85d7dc638",
   "metadata": {},
   "source": [
    "##### Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d92745-908a-4865-83d3-4e1fc05d79eb",
   "metadata": {},
   "source": [
    "**ANS:** \n",
    "The Random Forest Regressor is a machine learning algorithm used for regression tasks. It works by training an ensemble of decision trees, where each tree makes a prediction, and the final prediction is the average (or sometimes the median) of all the individual tree predictions. Random Forest Regressor is effective in capturing complex relationships in data, reducing overfitting, and providing robust predictions for continuous target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bd41e-8504-4929-899f-76ca0c405ccf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f73c679-d448-4341-b34b-9e2fff53b684",
   "metadata": {},
   "source": [
    "##### Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7d1f3-5d6b-4dc2-aa19-c0dc922415cd",
   "metadata": {},
   "source": [
    "**ANS:** Random Forest Regressor reduces overfitting by creating diverse trees, considering only subsets of features at each split, and combining predictions through averaging. This ensemble approach leads to a more generalized and robust regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153c3e3-a41b-4209-b37f-1db27c6d98f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "653142e5-1541-4853-87d7-b26f1e508b5c",
   "metadata": {},
   "source": [
    "##### Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982af017-5319-4c5e-bcc9-246a06de45e1",
   "metadata": {},
   "source": [
    "**ANS:** The Random Forest Regressor aggregates the predictions of multiple decision trees through a process called **averaging**.    \n",
    "\n",
    "Here's how it works:\n",
    "1. **Ensemble of Decision Trees:** The Random Forest Regressor builds an ensemble of decision trees, each trained on a different subset of the data using bagging(Bootstrap Aggregating).\n",
    "\n",
    "2. **Individual Tree Predictions:** Each decision tree in the ensemble independently makes predictions for the target variable based on the features of the input data.\n",
    "\n",
    "3. **Averaging Predictions:** In Regression, final prediction is obtained by averaging(mean) the predictions of all individual trees.\n",
    "\n",
    "4. **Weighted Averaging (Optional):** In some implementations, predictions may be weighted based on the performance or confidence of individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29075b9-67f7-4aad-8c5f-bfac3fb58489",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfcc9b1c-52c6-401f-82bb-0cee0148104b",
   "metadata": {},
   "source": [
    "##### Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ce97f-1ab1-4ca2-91a6-b5210a5c3da5",
   "metadata": {},
   "source": [
    "**ANS:** Random Forest Regressor has several hyperparameters that can be tuned to optimize the model’s performance. \n",
    "\n",
    "Here are some of the most commonly used hyperparameters:\n",
    "- **n_estimators:** The number of trees in the forest. The default value is 100, but it can be increased to improve the model’s accuracy.\n",
    "- **max_depth:** The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- **min_samples_split:** The minimum number of samples required to split an internal node. The default value is 2, but increasing it can help to prevent overfitting.\n",
    "- **min_samples_leaf:** The minimum number of samples required to be at a leaf node. The default value is 1, but increasing it can help to prevent overfitting.\n",
    "- **max_features:** The maximum number of features to consider when looking for the best split. The default value is “auto”, which means that all features are considered.\n",
    "\n",
    "Other hyperparameters include bootstrap, criterion, min_weight_fraction_leaf, max_leaf_nodes, min_impurity_decrease, oob_score, n_jobs, random_state, verbose, warm_start, and ccp_alpha1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc60c2-a1e4-45d1-b358-1e12e52c50f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99c31390-c21d-459c-9fbb-0f78036b11f0",
   "metadata": {},
   "source": [
    "##### Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa35a96-7d3e-401e-a041-4a659566af48",
   "metadata": {},
   "source": [
    "**ANS:**\n",
    "- **Random Forest Regressor** is an ensemble method that combines multiple decision trees to reduce overfitting and enhance robustness.   \n",
    "- **Decision Tree Regressor** builds a single tree and may be more prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10444b-f717-43a6-a83e-7148e15cc620",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e928c416-8120-495e-a273-27bcc002f9b3",
   "metadata": {},
   "source": [
    "##### Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221c409-a13d-48d8-b901-289ea5f0b863",
   "metadata": {},
   "source": [
    "**ANS: Advantages of Random Forest Regressor:**\n",
    "\n",
    "1. **Reduced Overfitting:**\n",
    "Ensemble of trees helps mitigate overfitting, providing more robust predictions.\n",
    "\n",
    "2. **High Accuracy:**\n",
    "Generally provides high accuracy by combining predictions from multiple trees.\n",
    "\n",
    "3. **Handles Missing Values:**\n",
    "Can effectively handle missing values in the dataset.\n",
    "\n",
    "4. **Feature Importance:**\n",
    "Provides a measure of feature importance, aiding in feature selection.\n",
    "\n",
    "5. **Robust to Outliers:**\n",
    "Robust to outliers and noise due to averaging predictions.\n",
    "\n",
    "6. **No Need for Feature Scaling:**\n",
    "Less sensitive to the scale of features, as it relies on relative feature importance.\n",
    "\n",
    "**Disadvantages of Random Forest Regressor:**\n",
    "\n",
    "1. **Complexity:**\n",
    "The model can become complex with a large number of trees, affecting interpretability.\n",
    "\n",
    "2. **Computational Cost:**\n",
    "raining and predicting can be computationally expensive, especially with a large number of trees.\n",
    "\n",
    "3. **Memory Usage:**\n",
    "Requires more memory due to storing multiple trees.\n",
    "\n",
    "4. **Biased Towards Dominant Classes:**\n",
    "May be biased toward dominant classes in imbalanced datasets.\n",
    "\n",
    "5. **Less Effective on Linear Relationships:**\n",
    "May not perform as well when the relationships in the data are primarily linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1de24-ddfa-450f-b7ff-5776030eeb96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "769c0d64-06f9-413f-971b-85bb65ed8869",
   "metadata": {},
   "source": [
    "##### Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262daf1-8723-47c9-87d4-022a81b026f7",
   "metadata": {},
   "source": [
    "**ANS:** The output of a Random Forest Regressor is a **continuous numerical** prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85882f5f-abfb-4b2b-8069-d3d3a0060fb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e25899-b4d8-4b54-9fde-5d517dd9a353",
   "metadata": {},
   "source": [
    "##### Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f02b8-7653-468f-8ca3-866d83539542",
   "metadata": {},
   "source": [
    "**ANS:** \n",
    "- Random Forest Regressor is a machine learning algorithm that is used for regression tasks. It is *not recommended to use Random Forest Regressor for classification tasks*.\n",
    "- Instead, **Random Forest Classifier** is the appropriate algorithm for classification tasks. The underlying mechanism remains the same —> building an ensemble of decision trees through bagging and combining predictions through voting. Each tree \"votes\" for a class, and the class with the majority of votes is considered the final prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
