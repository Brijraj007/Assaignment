{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f117d0-f9c1-44ad-b61f-06d095874976",
   "metadata": {},
   "source": [
    "##### Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431eaad-e5a1-4c38-9ca9-41d79e67804b",
   "metadata": {},
   "source": [
    "KNN stands for **K-Nearest Neighbors**. It is a **supervised learning algorithm** used for **classification and regression** problems. The algorithm predicts the label or value of a new data point by considering its K closest neighbors in the training dataset.\n",
    "\n",
    "The algorithm is based on the concept of **similarity**. It finds the K nearest neighbors to a given data point based on a distance metric, such as Euclidean distance. The class or value of the data point is then determined by the majority vote or average of the K neighbors .\n",
    "\n",
    "KNN is a **non-parametric method** that makes predictions based on the similarity of data points in a given dataset. It can handle both numerical and categorical data, making it a flexible choice for various types of datasets in classification and regression tasks.\n",
    "\n",
    "The algorithm is widely used in **pattern recognition**, **data mining**, and **intrusion detection**. It is also less sensitive to outliers compared to other algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7c19f-7315-4b24-97ff-c873f41b535f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24479c7c-1638-4f82-8959-2b55253d34e0",
   "metadata": {},
   "source": [
    "##### Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2046e-550a-47d5-aabb-767fa28de9fe",
   "metadata": {},
   "source": [
    "To choose the value of k in KNN, we can:\n",
    "\n",
    "1. Choose an odd number as the value of k.\n",
    "2. Set k=sqrt(n), where n is the number of data points.\n",
    "3. Run the KNN algorithm multiple times with different K values and use accuracy as the metric for evaluating K performance.\n",
    "4. Avoid choosing a very low value of k, as it will most likely lead to inaccurate predictions.\n",
    "5. The commonly used value of K is **5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7c45c-b487-4640-a3ce-b45d30b17a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb379ba-d34a-4efc-b91d-3cc70577ee5a",
   "metadata": {},
   "source": [
    "##### Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60faddc-6646-4d36-9db1-d8772118fac6",
   "metadata": {},
   "source": [
    "The key difference between KNN classifier and KNN regressor is the type of output they produce.\n",
    "- KNN classifier is used for classification tasks and attempts to predict the class to which the output variable belongs by computing the local probability. On the other hand, KNN regressor is used for regression tasks and attempts to predict the value of the output variable by using a local average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c968017-9f87-48d5-93f9-2fb3ae7a45fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "838ffed3-c5b8-4491-b1bb-668e103d09e0",
   "metadata": {},
   "source": [
    "##### Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05762f2e-0404-47bc-8845-794d5855f955",
   "metadata": {},
   "source": [
    "To measure the performance of KNN, we can use metrics such as **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "\n",
    "- _Accuracy_ is the most intuitive performance measure and is defined as the ratio of the number of correctly classified instances to the total number of instances. \n",
    "- _Precision_ is the ratio of correctly predicted positive instances to the total predicted positive instances. \n",
    "- _Recall_ is the ratio of correctly predicted positive instances to the total actual positive instances. \n",
    "- _F1 score_ is the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16944be-d00b-46d6-81bd-b6bc7db7dcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcce043-3686-4ff6-853a-b512e8275eda",
   "metadata": {},
   "source": [
    "##### Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31e75e-a71f-4a5f-9d62-52752779bd71",
   "metadata": {},
   "source": [
    "The curse of dimensionality is a phenomenon that occurs when the number of dimensions in a dataset increases, and the data becomes increasingly sparse. In KNN, this can lead to a situation where the nearest neighbors of a given point are not actually very close to it, making the algorithm less effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0b293-42f9-425f-b645-044cbb24e87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfcea6b0-2750-4cfa-bacb-5b07550b6981",
   "metadata": {},
   "source": [
    "##### Q6. How do you handle missing values in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf209f3-bc0f-4231-97e3-d7ac06c8b350",
   "metadata": {},
   "source": [
    "To handle missing values in KNN, you can use KNN imputation. This is a popular approach to missing data imputation, where a model is used to predict the missing values. The k-nearest neighbor (KNN) algorithm has proven to be generally effective for this task.\n",
    "\n",
    "Here’s how we can use KNN imputation to handle missing values in KNN:  \n",
    "1. Identify the missing values in your dataset and replace them with NaN values.\n",
    "2. Load the dataset into your KNN model.\n",
    "3. Use the KNN model to predict the missing values by finding the k-nearest neighbors of each instance with missing values and using their values to estimate the missing values.\n",
    "4. Replace the NaN values with the predicted values.\n",
    "\n",
    "Here’s an example code snippet that demonstrates how to use KNN imputation to handle missing values in KNN using the KNNImputer class from the sklearn.impute module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe06925d-08d3-4914-8734-aed5f67d9361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2.   6. ]\n",
      " [ 3.   4.   5. ]\n",
      " [ 5.5  6.   7. ]\n",
      " [ 8.   9.  10. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataset with missing values\n",
    "X = np.array([[1, 2, np.nan], [3, 4, 5], [np.nan, 6, 7], [8, 9, 10]])\n",
    "\n",
    "# Create a KNN imputer object\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Impute the missing values\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Print the imputed dataset\n",
    "print(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86299cb4-d8c5-4a4e-b347-67c013246449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd6b628-ecca-489d-8937-04eb951250f8",
   "metadata": {},
   "source": [
    "##### Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533ed3a-e197-4679-a969-0e9895d62a1b",
   "metadata": {},
   "source": [
    "The key difference between KNN classifier and KNN regressor is the type of output they produce. KNN classifier is used for classification tasks and attempts to predict the class to which the output variable belongs by computing the local probability. On the other hand, KNN regressor is used for regression tasks and attempts to predict the value of the output variable by using a local average.\n",
    "\n",
    "The performance of KNN classifier and KNN regressor depends on the nature of the problem at hand. In general, KNN classifier is better suited for problems where the output variable is categorical, while KNN regressor is better suited for problems where the output variable is continuous.\n",
    "\n",
    "For example, KNN classifier can be used to predict whether a given email is spam or not, while KNN regressor can be used to predict the price of a house based on its features such as location, size, and number of rooms.\n",
    "\n",
    "It’s important to note that the performance of KNN classifier and KNN regressor also depends on the choice of the value of k. Choosing the right value of k is crucial for the success of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee4590-aea2-4f2b-b5a2-38eec78a339f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c596ec4-f997-43ea-bc8b-3be63b5526b4",
   "metadata": {},
   "source": [
    "##### Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbf612-f11d-4b6a-9b6c-941b3787b6ec",
   "metadata": {},
   "source": [
    "The KNN algorithm has several strengths and weaknesses for both classification and regression tasks 1234. Here are some of them:\n",
    "\n",
    "Strengths:  \n",
    "- KNN is a simple and easy-to-understand algorithm that can be used for both classification and regression tasks.\n",
    "- KNN does not require any training, which saves computational resources.\n",
    "- KNN is robust to noisy data, as it relies on the majority vote of nearest neighbors.\n",
    "- KNN can be more effective for large datasets.\n",
    "\n",
    "Weaknesses:  \n",
    "- KNN can be computationally expensive, especially for large datasets.\n",
    "- KNN is sensitive to the choice of the value of k. Choosing the right value of k is crucial for the success of the algorithm.\n",
    "- KNN is sensitive to the distance metric used to compute the distance between data points.\n",
    "- KNN can be affected by the curse of dimensionality, which can lead to a situation where the nearest neighbors of a given point are not actually very close to it, making the algorithm less effective.\n",
    "To address these weaknesses, several modifications to the KNN algorithm have been proposed, such as using weighted distances, using feature selection techniques, and using dimensionality reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd1297-bcfe-42c9-9bdf-6104bd2f1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1747951d-3a84-46e1-a5be-148e4e8b04e0",
   "metadata": {},
   "source": [
    "##### Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf8367-402c-42b3-a265-eb03e05fa8d3",
   "metadata": {},
   "source": [
    "In KNN, the Euclidean distance and Manhattan distance are two commonly used distance metrics to measure the distance between two data points.\n",
    "The Euclidean distance is the straight-line distance between two points in a Euclidean space. It is calculated as the square root of the sum of the squared differences between the coordinates of the two points. The formula for Euclidean distance is:\n",
    "$$d(x,y) = \\sqrt{\\sum_{i=1}^{n}(y_i-x_i)^2}$$\n",
    "\n",
    "where x and y are two data points, and n is the number of dimensions.\n",
    "\n",
    "On the other hand, the Manhattan distance is the distance between two points measured along the axes at right angles. It is calculated as the sum of the absolute differences between the coordinates of the two points. The formula for Manhattan distance is:\n",
    "$$\\sqrt{\\sum_{i=1}^{n}|y_i-x_i|}$$\n",
    "where x and y are two data points, and n is the number of dimensions.\n",
    "The choice of distance metric depends on the nature of the problem at hand. In general, the Euclidean distance is more suitable for problems where the dimensions are continuous and have a physical interpretation, while the Manhattan distance is more suitable for problems where the dimensions are discrete or categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6a24c-124e-4727-b495-00fb3de2d87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0fac64-8a4a-4b9b-9b11-13255e023afa",
   "metadata": {},
   "source": [
    "##### Q10. What is the role of feature scaling in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c25adf-ddbb-4cf0-8892-5b302c429ee2",
   "metadata": {},
   "source": [
    "Feature scaling is an important preprocessing step for many machine learning algorithms, including KNN.\n",
    "\n",
    "The reason why feature scaling is required in KNN is that the algorithm is distance-based, and the distance between two data points is calculated using the Euclidean distance or Manhattan distance. If the features are not scaled, then the features with larger magnitudes will dominate the distance calculations, leading to inaccurate predictions.\n",
    "\n",
    "To overcome this problem, we can bring all the features to the same scale. One of the most common techniques to do so is normalization, where we calculate the mean and standard deviation of the variable. Then, for each observation, we subtract the mean and then divide by the standard deviation of that variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a9d80-ba34-4576-840b-b2f2fe235eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
